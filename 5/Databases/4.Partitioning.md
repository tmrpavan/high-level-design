## Data Partitioning - Sharding

Scalability of the distributed system is required to provide good performance when experiencing growth in the load. 
Data Partitioning is one of the techniques to improve performance of the distributed system.

### What is Data Partitioning?
Data partition is nothing but splitting a database into small instances and hosting in different nodes. Which are 
working together to provide better scalability and performance of the distributed system.

### There are two different ways of partitioning
1. Vertical Partitioning.
2. Horizontal Partitioning - Sharding

### Vertical Partitioning
Vertical Partitioning is nothing but split the columns of the table in to two or more tables. Put each table on a 
different server.

#### Advantages:
Vertical Partitioning increases the speed of the retrieval. We can split the columns which are holding more data like.

#### Disadvantages:
When we need to fetch data of multiple columns which are stored in different nodes then we need to use joins over the 
network. Which is too expensive.

### Horizontal Partitioning - Sharding
Horizontal Partitioning is also called Sharding. Sharding is nothing but split tables into two or more tables and store 
each table in different nodes.

### Methods to perform sharding
1. Key-Value based sharding
2. Hash based sharding

### Key-Value based sharding
In Key-Value based sharding we assign a continuous range of keys to a partition. These keys are called partition keys. 
A partition can have one or more than one key. Number of keys assigned to partitions no need to be equal; it can vary based on the requirement and the nature of data that we are storing. Application maps the key and partitions based on the partition keys to perform read and write operation.

![Key-Value Sharding.png](res/Key-Value%20Sharding.png)

#### Advantages:
1. Performance of the range query using partition key is improved. We can query the partition based on the key-range.

#### Disadvantages:
1. When we perform a range query on a secondary index we can not identify where the data stored we need to query all the 
shades.
2. If you do not partition the range properly some nodes can be a bottleneck due to most of the data stored in the one or 
two nodes. If frequently querying data stored in a single node that node can become a hotspot.

### Hash based sharding
In Hash based we define a hash function to get a unique hash code to the given key. We have to perform a mod operation 
with N - number of partitions to select the partition to store and retrieve the data.

If we have N nodes and the hash code is 1234. We need to calculate 1234 % N = X. X is the partition that is going to 
handle this request.

![Hash Sharding.png](res/Hash%20Sharding.png)

#### Advantages:
Data can be distributed uniformly to all partitions.

#### Disadvantages:
1. Add or Remove partitions is complex. Because we need to rehash the keys which need to be moved.
2. Range queries are complex to perform. We need to query all the partitions to get the result for the range query.

### Consistent Hashing
When we add or remove nodes is complex in hash based sharding, to overcome this issue we can use consistent hashing. 
In consistent hashing we assign a number to each node and hash the that and place it in a circle randomly based on the 
hash value. If a request comes we need to hash the key and place the request on the same circle. Now travel the circle 
clockwise then the node which appears first has to serve the request. When we remove a node the

#### Advantages:
Adding a node and removing nodes is simpler. When you add a new node traffic from the previous node is shared to the 
new node. When you remove a node the traffic will be rotated to the next node in the ring.

#### Disadvantages:
If you have multiple nodes failed there is a chance of more load being distributed to the next node. I will create a 
partition unbalancing issue.

### Rebalance the partitions

#### Avoid hash mod n
When we use hashcode  % n as a hash equation we may need to rehash the keys when we add or remove the node. So It is 
good to avoid this.

#### Fixed number of partitions
We fix the number of partitions to be created when we set up the database. When the new node is added we create a 
higher number of partitions and assign them to the all nodes to make sure all nodes are having equal partitions.

The drawback to this approach is the partitions are fixed. If the data is less and we create more partitions we may end 
up with less data in partitions. If we create less we may end up with more data in a single partition.

#### Dynamic partitioning
We set a threshold if partitions reached a particular threshold it will split into two and assigned to any one of the 
nodes. The same goes when you want to combine two partitions into one.

The drawback of this approach is, it is complex to dynamically split and combine the nodes.

#### Partition proportionally to nodes
We can maintain the proportionality between the nodes and partitions. When any node is added we can split the partitions
and assign equality. If anything is removed we can combine two more partitions as one.


### Partitioning and secondary indexes
If you want to perform range queries on other fields instead of using a partition key the query performance is 
decreased. To overcome this issue we need to create a secondary index based on the needs.

### There are two ways we can create
1. Secondary index by document - Local Index
2. Secondary index by team - Global Index

### Secondary index by document - Global index
This is also called a Local Index when we have multiple partitions we create a secondary index within the partition so 
it will be maintained inside the partitions.

The drawback of this approach is we need to query all the partitions we do not have any idea in which partition we have 
the data.

### Secondary index by team - Global Index
This is also called a Global Index. We can create a secondary index for all partitions in one pance and we can host it 
in a separate node.

We can query only the partitions which are having required data. But any modifications to the data we need to update 
the index as per the new data. It is read efficient and write intensive. 
